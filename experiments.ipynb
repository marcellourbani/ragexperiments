{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sentence_transformers torch ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[90.31377410888672, 69.97345733642578], [70.04136657714844, 91.45667266845703]]\n"
     ]
    }
   ],
   "source": [
    "def average_pool(last_hidden_states: Tensor,\n",
    "                 attention_mask: Tensor) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0) # nonmasked -> 0\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None] # average of masked, as attention_mask is 1 or 0\n",
    "\n",
    "input_texts = ['query: how much protein should a female eat',\n",
    "               'query: summit define',\n",
    "               \"passage: As a general guideline, the CDC's average requirement of protein for women ages 19 to 70 is 46 grams per day. But, as you can see from this chart, you'll need to increase that if you're expecting or training for a marathon. Check out the chart below to see how much protein you should be eating each day.\",\n",
    "               \"passage: Definition of summit for English Language Learners. : 1  the highest point of a mountain : the top of a mountain. : 2  the highest level. : 3  a meeting or series of meetings between the leaders of two or more governments.\"]\n",
    "tokenizer = AutoTokenizer.from_pretrained('./data/original')\n",
    "model = AutoModel.from_pretrained('./data/original')\n",
    "\n",
    "# Tokenize the input texts\n",
    "batch_dict = tokenizer(input_texts, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "outputs = model(**batch_dict)\n",
    "embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "\n",
    "# normalize embeddings\n",
    "embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "scores = (embeddings[:2] @ embeddings[2:].T) * 100\n",
    "print(scores.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('./data/original')\n",
    "model = AutoModel.from_pretrained('./data/original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 5, 5, 5],\n",
       "        [5, 5, 3, 5]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "v1=torch.tensor([[1,1,1,1],[1,1,1,1]])\n",
    "v2=v1*3\n",
    "v1[1][2]=0\n",
    "v2.masked_fill(v1.bool(),5)\n",
    "# v1.bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 3])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_dict['attention_mask'].bool().shape\n",
    "# torch.Size([4, 75])\n",
    "# batch_dict['attention_mask'][...,None].bool().shape\n",
    "# torch.Size([4, 75, 1])\n",
    "# v1[...,None]\n",
    "# batch_dict['attention_mask'].sum(dim=1).shape\n",
    "v1.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbedTest:\n",
    "    def __init__(self) -> None:\n",
    "        self._tokenizer = AutoTokenizer.from_pretrained('./data/original')\n",
    "        self._model = AutoModel.from_pretrained('./data/original')\n",
    "    def _average_pool(self,last_hidden_states: Tensor,\n",
    "                 attention_mask: Tensor) -> Tensor:\n",
    "        last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0) # nonmasked -> 0\n",
    "        return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None] # average of masked, as attention_mask is 1 or 0\n",
    "    def generateEmbeddings(self,texts):\n",
    "        batch_dict = self._tokenizer(texts, max_length=512, padding=True, truncation=True, return_tensors='pt')      \n",
    "        outputs = self._model(**batch_dict)\n",
    "        embeddings = self._average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "\n",
    "        # normalize embeddings\n",
    "        return F.normalize(embeddings, p=2, dim=1)\n",
    "\n",
    "embedder = EmbedTest()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate article embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def readArticle(id):\n",
    "     with open(f\"./data/articles/{id}\") as f:\n",
    "         article = json.load(f)\n",
    "         text = BeautifulSoup(article[\"body\"]).get_text()\n",
    "         [embedding] = embedder.generateEmbeddings([f\"passage:{text}\"])\n",
    "         return (article[\"id\"],article[\"name\"],embedding)\n",
    "\n",
    "artfiles = os.listdir(\"./data/articles/\")\n",
    "articles = list(map(readArticle,artfiles))\n",
    "\n",
    "with open(\"./data/trained/articles.dat\",\"wb\") as f:\n",
    "    pickle.dump(articles,f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read articles and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/trained/articles.dat\",\"rb\") as f:\n",
    "    articles = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81.06541442871094, 13862240080285, 'ActiveControl Error: (addtobuffer has problems with data- and/or cofile)', 'https://support.basistechnologies.com/hc/en-us/articles/13862240080285')\n",
      "(81.03059387207031, 14868550624541, 'ActiveControl How To: Configured to send automated e-mails notifications?', 'https://support.basistechnologies.com/hc/en-us/articles/14868550624541')\n",
      "(81.021240234375, 13430714503453, 'ActiveControl How to: Stop Auto-Import Jobs from De-scheduling', 'https://support.basistechnologies.com/hc/en-us/articles/13430714503453')\n",
      "(80.37882232666016, 14706112950173, 'Errors about \"unprocessed linkages\" and \"linkages with errors\" when running Test Impact Radar (0043)', 'https://support.basistechnologies.com/hc/en-us/articles/14706112950173')\n",
      "(79.86550903320312, 14111832764829, 'Can we manage client 000 using ActiveControl (create and import transports)? ', 'https://support.basistechnologies.com/hc/en-us/articles/14111832764829')\n",
      "\n",
      "(74.66816711425781, 211706683, 'Why do I not get the Transport Form popup in SAPGUI when saving/releasing transports?', 'https://support.basistechnologies.com/hc/en-us/articles/211706683')\n",
      "(74.65156555175781, 360000417426, 'HOW DO I: setup  0060: Deep Impact Analysis (since AC7.0)', 'https://support.basistechnologies.com/hc/en-us/articles/360000417426')\n",
      "(74.38163757324219, 14001679259549, 'BPEM as Not Showing to be Routed in Dynamic Work Center', 'https://support.basistechnologies.com/hc/en-us/articles/14001679259549')\n",
      "(74.29508972167969, 13383790488989, 'ActiveControl What does a blank transport indicate? (Description, Location, Owner, Group, etc. are blank)', 'https://support.basistechnologies.com/hc/en-us/articles/13383790488989')\n",
      "(73.77218627929688, 13523416509469, 'ActiveControl Error: (User clicked continue after receiving a popup warning about an inline conflict, the system hangs and the screen times-out)', 'https://support.basistechnologies.com/hc/en-us/articles/13523416509469')\n",
      "\n",
      "(78.37126159667969, 13383790488989, 'ActiveControl What does a blank transport indicate? (Description, Location, Owner, Group, etc. are blank)', 'https://support.basistechnologies.com/hc/en-us/articles/13383790488989')\n",
      "(78.11357879638672, 15173170957725, 'ActiveControl How To: View the Owner field on the /BTI/TE_RACTIVITY_EVENTS report?', 'https://support.basistechnologies.com/hc/en-us/articles/15173170957725')\n",
      "(77.44822692871094, 14290031810589, 'Activating the Enhanced Check Dependencies (0030) using INCLUDE_ALL_TRS.', 'https://support.basistechnologies.com/hc/en-us/articles/14290031810589')\n",
      "(76.2269515991211, 14868550624541, 'ActiveControl How To: Configured to send automated e-mails notifications?', 'https://support.basistechnologies.com/hc/en-us/articles/14868550624541')\n",
      "(75.73189544677734, 360054175172, 'HOW DO I: mimic the Pre-Deployment Approval in ChaRM with ActiveControl.', 'https://support.basistechnologies.com/hc/en-us/articles/360054175172')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def lookup(q):\n",
    "    [queryembed] = embedder.generateEmbeddings(f\"query:{q}\")\n",
    "    def score(art):\n",
    "         return (((art[2] @ queryembed) * 100).item(),art)\n",
    "    scored = list(map(score, articles))\n",
    "    scored.sort(reverse=True)\n",
    "    def extract(art):\n",
    "         return (art[0],art[1][0],art[1][1],f\"https://support.basistechnologies.com/hc/en-us/articles/{art[1][0]}\")\n",
    "    return list(map(extract,scored[0:5]))\n",
    "\n",
    "def test(query):\n",
    "     result = lookup(query)\n",
    "     for r in result:\n",
    "          print(r)\n",
    "     print()\n",
    "\n",
    "# print(lookup(\"task\"))\n",
    "\n",
    "# print(lookup(\"short dump\"))\n",
    "# print(lookup(\"test impact\"))\n",
    "\n",
    "test(\"import errors\")\n",
    "test(\"unexpected result\")\n",
    "test(\"task\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
