{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RAG system for zendesk articles based on ollama\n",
    "Assumes documents were downloaded with [this script](./download.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "import pickle\n",
    "ollama_host=\"http://ollama:11434\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"llama3\",base_url=ollama_host)\n",
    "\n",
    "def getEmbeddings():\n",
    "    cache = './data/cache/articleembeddings_zdollama.pkl'\n",
    "    try:\n",
    "        with open(cache,\"rb\") as inp:\n",
    "            return pickle.load(inp)\n",
    "    except IOError:\n",
    "        loader = TextLoader(\"./data/samplearticle.txt\",encoding=\"utf-8\")\n",
    "        data=loader.load()\n",
    "        text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "        data = text_splitter.split_documents(data)\n",
    "        embeddings = OllamaEmbeddings(base_url=ollama_host)\n",
    "        vectorstore = FAISS.from_documents(data, embedding=embeddings)\n",
    "        with open(cache,\"wb\") as out:\n",
    "            pickle.dump(vectorstore,out,pickle.DEFAULT_PROTOCOL)\n",
    "        return vectorstore\n",
    "vectorstore = getEmbeddings()\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/ragtest/.condaenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, it seems that the topic of discussion is around using transports of copies (TOCs) in SAP ActiveControl. From the information provided, it appears that TOCs can be created at different levels (transport, task, or project) and can have a different transport description than the original source transport.\\n\\nThe context also mentions that before ActiveControl 8.0, TOCs were given a transport description equal to the business task subject, which could cause confusion in scenarios where multiple different source transports were linked to the same business task. To address this issue, the new TOC capability allows for the creation of TOCs with a different transport description than the original source transport.\\n\\nAs for why someone would use a transport of copies, it seems that the answer is not explicitly provided in the context. However, based on the information provided, it can be inferred that TOCs can be useful in scenarios where multiple transports are linked to the same business task and you want to keep track of which transport is being used for each landscape or path. By using a transport of copies, you can create a separate copy of the transport for each landscape or path, allowing you to maintain control over which transport is being used for each one.\\n\\nIn summary, the context provides information on how TOCs can be created at different levels and how they can have a different transport description than the original source transport. However, it does not explicitly explain why someone would use a transport of copies, so that is an area where further clarification or details might be helpful.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Why would I use a transport of copies?\"\n",
    "result = conversation_chain({\"question\": query})\n",
    "answer = result[\"answer\"]\n",
    "answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
