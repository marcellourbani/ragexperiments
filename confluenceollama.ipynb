{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RAG system for confluence articles based on ollama\n",
    "Assumes documents were downloaded with [this script](./scrapers/scrapeconfluence.ipynb) and stored in a postgres database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain langchain_community pgvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## configuration\n",
    "ollama_host=\"http://ollama:11434\"\n",
    "chatmodel= \"llama3\"\n",
    "embedmodel=\"mxbai-embed-large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass,asdict\n",
    "from dotenv import dotenv_values\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.document_loaders import BaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts.chat import SystemMessagePromptTemplate,HumanMessagePromptTemplate,ChatPromptTemplate\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import pgvector\n",
    "from psycopg.rows import class_row\n",
    "from typing import Iterable, Iterator\n",
    "import psycopg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Article:\n",
    "    id:str\n",
    "    parent:str\n",
    "    version:int\n",
    "    title:str\n",
    "    status:str\n",
    "    hasvectors:bool = False\n",
    "    def dict(self):\n",
    "        return {k: str(v) for k, v in asdict(self).items()}\n",
    "\n",
    "@dataclass\n",
    "class ArticleText:\n",
    "    id:str\n",
    "    title:str\n",
    "    contents:str\n",
    "    def __str__(self) -> str:\n",
    "        return f'{self.title}\\n{self.contents}'\n",
    "\n",
    "def connectStr(alchemy=False): \n",
    "    if alchemy: return f'postgresql+psycopg://postgres:{dotenv_values()[\"POSTGRES_PASSWORD\"]}@pgvector:5432/ragtest'\n",
    "    return  f'host=pgvector dbname=ragtest user=postgres password={dotenv_values()[\"POSTGRES_PASSWORD\"]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/ragtest/.condaenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:141: LangChainPendingDeprecationWarning: This class is pending deprecation and may be removed in a future version. You can swap to using the `PGVector` implementation in `langchain_postgres`. Please read the guidelines in the doc-string of this class to follow prior to migrating as there are some differences between the implementations. See <https://github.com/langchain-ai/langchain-postgres> for details aboutthe new implementation.\n",
      "  warn_deprecated(\n",
      "/workspaces/ragtest/.condaenv/lib/python3.11/site-packages/langchain_community/vectorstores/pgvector.py:328: LangChainPendingDeprecationWarning: Please use JSONB instead of JSON for metadata. This change will allow for more efficient querying that involves filtering based on metadata.Please note that filtering operators have been changed when using JSOB metadata to be prefixed with a $ sign to avoid name collisions with columns. If you're using an existing database, you will need to create adb migration for your metadata column to be JSONB and update your queries to use the new operators. \n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "#generate embeddings\n",
    "class PostgresLoader(BaseLoader):\n",
    "    def __init__(self,length:int,mincontentlen=200):\n",
    "        self.length = length\n",
    "        self.mincontentlen= mincontentlen\n",
    "    def lazy_load(self) -> Iterator[Document]:\n",
    "        with psycopg.connect(connectStr()) as conn:\n",
    "            with conn.cursor(row_factory=class_row(ArticleText)) as cur:\n",
    "                query = f'''select articles.id, title, contents from articles INNER JOIN articlescontents ON articlescontents.id = articles.id \n",
    "                            where hasvectors = false and length(contents) > {self.mincontentlen} LIMIT {self.length}'''\n",
    "                cur.execute(bytes(query,\"utf-8\"))\n",
    "                article = cur.fetchone()\n",
    "                while article!=None:\n",
    "                    yield  Document(str(article),path= article.id,metadata = {\"source\": article.id})\n",
    "                    article = cur.fetchone()\n",
    "def markasread(id ):\n",
    "    with psycopg.connect(connectStr()) as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            query = f'update articles set hasvectors = true where id = \\'{id}\\''\n",
    "            cur.execute(bytes(query,\"utf-8\"))\n",
    "            \n",
    "def getVectorStore():\n",
    "    embeddings = OllamaEmbeddings(base_url=ollama_host,model=embedmodel)\n",
    "    return pgvector.PGVector(connectStr(True),embeddings)    \n",
    "\n",
    "\n",
    "def loadEmbeddings(n=10):\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    vectorstore = getVectorStore()\n",
    "    for  doc in PostgresLoader(n).lazy_load():\n",
    "        chunks = text_splitter.split_documents([doc])\n",
    "        vectorstore.add_documents(chunks)\n",
    "        markasread(doc.metadata.get(\"source\"))\n",
    "\n",
    "loadEmbeddings(30000)\n",
    "# markasread(\"70516867\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/ragtest/.condaenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '2359337524'}, page_content='HOW DO I: control the distribution of particular transports to particular SAP clients through the landscape?\\nQuestion\\n: Is it possible within ActiveControl to\\xa0distribute particular transports to particular SAP clients through the landscape?\\n\\xa0\\nAnswer\\n:\\nVersion 6.20 adds the capability to distribute transports to particular system clients of an SAP landscape, based on rules and the source client of the transport.\\nThis requirement had previously been delivered as a custom enhancement for a customer wanting to distribute transports to clients in their Production system for seperate business entities, but has now been enhanced and added to standard ActiveControl for any other customers wanting to benefit from this capability.\\n\\xa0\\nConfiguration\\n1) Populate /BTI/TE_IMP_CLI table in the Domain Controller with your required transport distribution rules\\nField label / [technical field name]\\xa0\\nPath ID [PATH]\\n: the AC path for which the rule is being defined\\nSource\\n\\xa0system\\n\\xa0[SOURCESYSTEM]\\n: the source system (\\nSID\\n) (always the dev system) \\n*\\nSource\\n\\xa0client\\n\\xa0[SOURCECLIENT]\\n: the source system client \\n*\\nTarget ID [TARGET]\\n: the target system in the path where the transport has/not to be imported into particular client\\nSort\\nField [SORTORDER]\\n: used for sorting the clients in a particular target\\nTarget client [TARG\\nCLIENT]\\n: The client of the target system\\nIndicator [SKIP]\\n: An X should be entered in this field for the rules where you want the transport to\\xa0\\nnot\\n\\xa0be imported into the defined client defined in the rest of the rule\\n\\xa0\\n*\\nFor merge transports, the source SID and client of the original transport are used.\\n2) Switch on /BTI/TE_EXIT_SAMPLE_0065 in /BTI/TE_EXITC table in the Domain Controller.\\nNotes:\\ni) the import queue is not skipped, it is during the import that the skipping occurs based on the rules defined in the configuration table\\nii) the clients will be sorted based on\\xa0\\nSORTORDER\\n\\xa0\\niii) if a client is not defined in the configuration it will be ignored\\niiii) if no entries are found for a transport it will be imported in all the clients defined in the config\\niv) the transports can still be imported using both single one-by-one or block import.\\nv) this functionality is really only for transport distribution from Development through the subsequent targets in a path.\\nIt is NOT possible to use this functionality during the standard Merge process (as Merge process will import the source transport into all configured clients of the Development target (and then create the Merge TOC in one of those clients). If you really want to achieve Merge to specific client, the solution would be to configure multiple Merge targets, each with one client.'),\n",
       " Document(metadata={'source': '2359696748'}, page_content='HOW DO I: add an external transport into ActiveControl ? (version 6.20 onwards, Windows GUI)\\nQuestion\\n: \\xa0\\nHow do I add an external transport into ActiveControl ?\\n\\xa0\\nAnswer\\n: \\xa0\\xa0\\nNew functionality since 6.20 simplifies the process for adding external third-party transports into ActiveControl , avoiding the historical steps that needed to be done in the\\xa0SAP\\xa0backend.\\nIt is now possible to upload the cofile and data file for the external transport into\\xa0SAP\\xa0from directly within the ActiveControl Windows\\xa0GUI, via new\\xa0\\nExternal Transport Request\\n\\xa0option on the [New Transport Form] screen.\\nThese files can be added either to the ActiveControl Domain Controller, or to a specific local development system.\\nAn ActiveControl Transport Form can then be populated for the transport, and moved through the workflow in the usual manner.\\n\\xa0\\nNotes\\nYou do NOT need to create\\xa0RFCs as ActiveControl will use existing\\xa0RFCs to get the transport files.\\nYou do NOT need to create Targets in the Windows GUI for each of the external system\\xa0SIDs. (these will get created automatically by ActiveControl)\\nSince you can only add a Transport to one path, you should use\\xa0TOCs if you need to get the same transport into multiple system paths in your landscape.\\nThe default behaviour of ActiveControl is that client dependent transports will stop in the Import Queue of the Development AC Target (if it has multiple clients configured), but a client independent transport will go straight to the first location after the Import Queue.\\xa0 Since you would typically always want External Transports to stop in the Dev Import Queue you could create a Skipping rule to force External Transports (ie with the TF [Type] = \"External Transports\" (or similar) to STOP in the Import Queue.\\nIn case your company is using a lot of external transports, and many external transports with the same SID (e.g. X01) need to go to different system tracks, then you would need to change the settings in the table /BTI/TE_TARG_EXT table a lot. In that table, an external transport SID is connected to a fixed Target and Path.\\nIn case you don\\'t want - or are not allowed - to make these changes in the table /BTI/TE_TARG_EXT table a lot, you might want to use the solution where you don\\'t need to change this table a lot anymore.\\nSee FAQ: \\nActiveControl Change Notes: TE-5398 : Enhanced External Transports - SID not linked to particular Target/Path - Customer Support Desk (basistechnologies.com)'),\n",
       " Document(metadata={'source': '2359893796'}, page_content='Why is a transport I imported via ActiveControl not imported to all SAP system clients?\\nIssue\\n:\\nI have created a test transport, but when it is imported via ActiveControl (either manually or with an automated Schedule), it is not going into all the clients when we look in the SAP logs (or on the Transport Form , even though they are configured within the ActiveControl Configuration.\\n\\xa0\\nAnswer\\n:\\nThe likely reason for this is that the transport is client independent.\\nClient independent transports are only imported into main/first client via an import through ActiveControl - whereas client dependant transports are imported into all clients specified in the target configuration. \\nNote that blank transports are treated by SAP as client independent since they contain no SAP objects.\\n\\xa0\\nIf you do not believe this is the reason for your particular transport not being imported to all clients, please raise a support ticket with Basis Technologies.'),\n",
       " Document(metadata={'source': '2359656883'}, page_content='Error: \"addtobuffer has problems with data- and/or cofile\"\\nError: \\n(Error text: addtobuffer has problems with data- and/or cofile Request: <SID>Kxxxxxx)\\nWhen AC adds a request to the import queue of a system, you get error \\n\"Transport control program tp ended with error code 0247\"\\nCommand: ADDTOBUFFER <transport request> <SID> pf=\\\\\\\\gcltest\\\\sapmnt\\\\tra\\nReturn code: 0247\\nError text: addtobuffer has problems with data- and/or cofile\\nRequest:\\n <SID>Kxxxxxx\\n*Alternatively you may get the following error when you use tp command:\\nThis is tp version xxx.xx.xx for ANY database\\nAddtobuffer failed for <TR>.\\nNeither datafile nor cofile exist (cofile may also be corrupted).\\nOutput from tools called by tp:\\ntp returncode summary:\\nTOOLS: Highest return code of single steps was: 0\\nERRORS: Highest tp internal error was: 0247\\nYou can also find the following error details:\\nTransport control program tp ends with error code 0247\\n\\xa0 \\xa0 Message no. XT 200\\nDiagnosis\\n\\xa0 \\xa0 An error occurred when executing a tp command.\\n\\xa0 \\xa0 \\xa0 Command:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 ADDTOBUFFER <TR>\\xa0<SID> pf=/usr/sap/trans/bin/...\\n\\xa0 \\xa0 \\xa0 Return code:\\xa0\\xa0\\xa0 0247\\n\\xa0 \\xa0 \\xa0 Error text:\\xa0\\xa0\\xa0\\xa0 addtobuffer has problems with data- and/or cofile\\n\\xa0 \\xa0 \\xa0 Request:\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 <TR>\\nSystem Response\\n\\xa0 \\xa0 The function terminates.\\nProcedure\\n\\xa0 \\xa0 Correct the error and execute the command again if necessary.\\nAnswer:\\nThe root cause is that tp can not find the cofile and data file. This may have the following reasons:\\nThe data file or cofile of the transport request does not exist in <DIR_TRANS>/data or <DIR_TRANS>/cofiles。\\nThe data file and cofile exist in <DIR_TRANS>/data and <DIR_TRANS>/cofiles, but due to case sensitive in Unix systems, they can not be recognized.\\nDue to network connection issues, the connection to\\xa0<DIR_TRANS> is not applicable.\\nThe permission to <DIR_TRANS>/data or <DIR_TRANS>/cofiles\\xa0is not OK.\\nThe permission to the problematice data file or cofile is not OK.\\n\\xa0\\nSteps:\\n\\xa0( You can manually copy the data file and cofile to the <DIR_TRANS>/data and <DIR_TRANS>/cofiles.\\xa0\\nIf you are using separate transport directories and the transport file can be transferred between transport directories, then you can click \"Adjust Import Queue\" in the import queue to adjust it.\\xa0 You can also use schedule the report RSTMSTIQ as a periodic background job, the import queues will be automatically adjusted (the datafile and cofiles will be automatically copied from one transport directory to the other). )\\n\\xa0(Use the same name(usually\\xa0in\\xa0upper case)\\xa0of cofile and data file where you get it.)\\n\\xa0(Check if you can access <DIR_TRANS> and all of its sub folders. If not, resolve the network connection issue. )\\n\\xa0(Correct the permissions\\xa0to <DIR_TRANS>/data and <DIR_TRANS>/cofiles. Especially when you have several application servers, you should make sure you have read and write access to the transport directory and all its subfolders from each application server.)\\nCheck the permission to the problematic files, 664 is required at least. Please change it to 777 to see if it works.\\n**Note**\\nSee Also\\n2506805\\n\\xa0- Transport Directory DIR_TRANS\\n2450147\\n\\xa0- You got errors like \"cant open \" or \"permission denied\" during transport\\nKeywords\\nTMS_MGR_FORWARD_TR_REQUEST,TMS_TP_MAINTAIN_BUFFER, TP_REPORTED_ERROR, addtobuffer, 0247, RSTMSTIQ')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw vector search\n",
    "retriever = getVectorStore().as_retriever()\n",
    "retriever.get_relevant_documents(\"how do I import a transport in different clients?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/ragtest/.condaenv/lib/python3.11/site-packages/langchain_community/vectorstores/pgvector.py:328: LangChainPendingDeprecationWarning: Please use JSONB instead of JSON for metadata. This change will allow for more efficient querying that involves filtering based on metadata.Please note that filtering operators have been changed when using JSOB metadata to be prefixed with a $ sign to avoid name collisions with columns. If you're using an existing database, you will need to create adb migration for your metadata column to be JSONB and update your queries to use the new operators. \n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# create a chatbot\n",
    "llm = Ollama(model=chatmodel,base_url=ollama_host)\n",
    "\n",
    "general_system_template = r\"\"\" \n",
    "Given a specific context, please give a short answer to the question, covering the required advices in general and then provide the names all of relevant(even if it relates a bit) products.\n",
    "Always include a reference to the source document \n",
    " ----\n",
    "{context}\n",
    "----\n",
    "\"\"\"\n",
    "general_user_template = \"Question:```{question}```\"\n",
    "messages = [\n",
    "            SystemMessagePromptTemplate.from_template(general_system_template),\n",
    "            HumanMessagePromptTemplate.from_template(general_user_template)\n",
    "]\n",
    "qa_prompt = ChatPromptTemplate.from_messages( messages )\n",
    "\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=getVectorStore().as_retriever(),\n",
    "    memory=memory,\n",
    "    combine_docs_chain_kwargs={'prompt': qa_prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To control the distribution of particular transports to particular SAP clients through the landscape, follow these steps:\\n\\n1. Populate the `/BTI/TE_IMP_CLI` table in the Domain Controller with your required transport distribution rules.\\n2. Switch on the `/BTI/TE_EXIT_SAMPLE_0065` exit in the `/BTI/TE_EXITC` table in the Domain Controller.\\n\\nNotes:\\n\\n* The import queue is not skipped; it's during the import that the skipping occurs based on the rules defined in the configuration table.\\n* Clients will be sorted based on `SORTORDER`.\\n* If a client is not defined in the configuration, it will be ignored.\\n* If no entries are found for a transport, it will be imported into all clients defined in the config.\\n* This functionality is only for transport distribution from Development through the subsequent targets in a path. It's not possible to use this functionality during the standard Merge process.\\n\\nProducts:\\n\\n* ActiveControl\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How do I choose the clients where a transport will be imported?\"\n",
    "result = conversation_chain({\"question\": query})\n",
    "answer = result[\"answer\"]\n",
    "answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
